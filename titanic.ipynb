{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/github/sahinozan/Titanic/blob/master/titanic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Preparation\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 Importing Libraries\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_predict, cross_validate, RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.set_printoptions(precision=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Optional Style Settings\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['savefig.dpi'] = 200\n",
    "sns.set(rc={\"figure.dpi\": 200, 'savefig.dpi': 200})\n",
    "sns.set_context('notebook')\n",
    "sns.set_style(\"ticks\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 Load Dataset\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('https://raw.githubusercontent.com/sahinozan/Titanic/master/train.csv')\n",
    "df_test = pd.read_csv('https://raw.githubusercontent.com/sahinozan/Titanic/master/test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3 Checking Null Values\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(data=[df_train.isna().sum(), df_test.isna().sum()], index=['Train', 'Test']).T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Age** and **Cabin** features have too many null values. **Embarked** feature has 2 null values in Train data. **Fare** feature has a single null value in Test data.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4 Checking Duplicate Values\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Number of duplicate values in train data: {df_train.duplicated().sum()}')\n",
    "print(f'Number of duplicate values in test data: {df_test.duplicated().sum()}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are no duplicate values in train and test data.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.5 Checking Dataset Features\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have 12 features in the dataset.\n",
    "\n",
    "- **PassengerId**: Identification number of the passenger\n",
    "- **Survival**: Whether a passenger survived or not (0 or 1)\n",
    "- **Pclass**: The socio-economic class\n",
    "  - Upper: 1\n",
    "  - Middle 2\n",
    "  - Lower: 3\n",
    "- **Name**: Name of the passenger\n",
    "- **Sex**: Gender of the passenger (Male or Female)\n",
    "- **Age**: Age of the passenger in years\n",
    "- **SibSp**: Number of siblings / spouses aboard\n",
    "- **Parch**: Number of parents / children aboard\n",
    "- **Ticket**: Ticket Number\n",
    "- **Fare**: Passenger Fare\n",
    "- **Cabin**: Cabin Number\n",
    "- **Embarked**: Port of Embarkation\n",
    "  - C: Cherbourg\n",
    "  - Q: Queenstown\n",
    "  - S: Southampton\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Numerical:\n",
    "\n",
    "- **Age**, **SibSp**, **Parch**, and **Fare**\n",
    "\n",
    "Categorical:\n",
    "\n",
    "- **Survival**, **Pclass**, **Sex**, **Ticket**, **Cabin**, and **Embarked**, **Name**, **PassengerId**\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Name**, **Sex**, **Ticket**, **Cabin**, and **Embarked** features are `object` type. **Sex** and **Embarked** features consists of only a few values therefore, we will convert them into the `category` type to increase efficiency.\n",
    "\n",
    "> **Name**, **Ticket**, and **Cabin** features will not be in the training set so, we will not convert them into `category` type.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train[['Sex', 'Embarked']] = df_train[['Sex', 'Embarked']].astype('category')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Exploratory Data Analysis\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1 Univariate Analysis\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will analyze and visualize features separately to understand the data in depth. We will use bar plot and pie chart for `categorical` features. We will use histogram and box plot for `numerical` features."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is a custom function for bar plots. We will use this function to annotate exact counts of the features."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def bar_plot_annotate(axes, column):\n",
    "    for _i in range(len(df_train[column].dropna().unique())):\n",
    "        _x = axes.patches[_i].get_x() + axes.patches[_i].get_width() / 2\n",
    "        _y = axes.patches[_i].get_height() / 2\n",
    "        axes.annotate(\n",
    "            text=df_train.groupby(column).agg({'Ticket': 'count'}).loc[df_train[column].unique()[_i], 'Ticket'],\n",
    "            xy=(_x, _y), ha='center', va='center')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1.1 Analysis of Survived\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 2, figsize=(20, 7))\n",
    "g = sns.countplot(data=df_train, x='Survived', ax=ax[0])\n",
    "ax[0].set_title('Bar Chart')\n",
    "\n",
    "df_train['Survived'].value_counts().plot(kind='pie', autopct=\"%1.1f%%\", ax=ax[1])\n",
    "ax[1].set_title('Pie Chart')\n",
    "\n",
    "bar_plot_annotate(g, 'Survived')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will analyze to find out what caused **38.4%** of the passengers to survive.\n",
    "\n",
    "- **61.6%** of the passengers did **not** survive.\n",
    "- Only **38.4%** of the passengers did survive.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1.2 Analysis of Sex\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 2, figsize=(20, 7))\n",
    "g = sns.countplot(data=df_train, x='Sex', order=['male', 'female'], ax=ax[0])\n",
    "ax[0].set_title('Bar Chart')\n",
    "\n",
    "df_train['Sex'].value_counts().plot(kind='pie', autopct=\"%1.1f%%\", ax=ax[1])\n",
    "ax[1].set_title('Pie Chart')\n",
    "\n",
    "bar_plot_annotate(g, 'Sex')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- **64.8%** of the passengers are **Male**.\n",
    "- Only **35.2%** of the passengers are **Female**.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1.3 Analysis of Age\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 2, figsize=(20, 7))\n",
    "sns.histplot(data=df_train, x='Age', kde=True, ax=ax[0])\n",
    "ax[0].set_title('Age Distribution Histogram')\n",
    "\n",
    "sns.boxplot(data=df_train, x='Age', ax=ax[1])\n",
    "ax[1].set_title('Age Distribution Boxplot')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Average Age: {df_train[\"Age\"].mean()}')\n",
    "print(f'Lowest Age: {df_train[\"Age\"].min()}')\n",
    "print(f'Highest Age: {df_train[\"Age\"].max()}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "number_of_people = max(dict(df_train[\"Age\"].value_counts()).values())\n",
    "most_frequent_age = [key for key, value in dict(df_train[\"Age\"].value_counts()).items() if value == number_of_people]\n",
    "print(f'Most frequent age is {most_frequent_age[0]} with {number_of_people} passengers.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Age of the passengers varies from **0.42** to **80** years with an average of **29.7**.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1.4 Analysis of Fare\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 2, figsize=(20, 7))\n",
    "sns.histplot(data=df_train, x='Fare', kde=True, ax=ax[0])\n",
    "ax[0].set_title('Fare Distribution Histogram')\n",
    "\n",
    "sns.boxplot(data=df_train, x='Fare', ax=ax[1])\n",
    "ax[1].set_title('Fare Distribution Boxplot')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Average Fare: ${df_train[\"Fare\"].mean():.2f}')\n",
    "print(f'Lowest Fare: ${df_train[\"Fare\"].min()}')\n",
    "print(f'Highest Fare: ${df_train[\"Fare\"].max():.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Number of passengers who paid $0.0: ', df_train[df_train[\"Fare\"] == df_train[\"Fare\"].min()].shape[0])\n",
    "print('Number of passengers who paid $512.33: ', df_train[df_train[\"Fare\"] == df_train[\"Fare\"].max()].shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "number_of_people = max(dict(df_train[\"Fare\"].value_counts()).values())\n",
    "most_frequent_fare = [key for key, value in dict(df_train[\"Fare\"].value_counts()).items() if value == number_of_people]\n",
    "print(f'Most frequent fare is ${most_frequent_fare[0]} which is paid by {number_of_people} passengers.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- There are passengers who did **not** pay for the cruise.\n",
    "- Only 3 passengers paid **512.33** dollars.\n",
    "- 15 passengers paid **0.0** dollars.\n",
    "- Average fare is **32.2** dollars.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1.5 Analysis of Pclass\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 2, figsize=(20, 7))\n",
    "g = sns.countplot(data=df_train, x='Pclass', order=[3, 1, 2], ax=ax[0])\n",
    "ax[0].set_title('Bar Chart')\n",
    "\n",
    "df_train['Pclass'].value_counts().plot(kind='pie', autopct=\"%1.1f%%\", ax=ax[1])\n",
    "ax[1].set_title('Pie Chart')\n",
    "\n",
    "bar_plot_annotate(g, 'Pclass')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**55.1%** of the passengers have 3rd class ticket. Meanwhile, the number of passengers who have 1st and 2nd class ticket are quite close with **24.2%** and **20.7%** respectively.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1.6 Analysis of SibSp and Parch\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(2, 2, figsize=(20, 12))\n",
    "sns.histplot(data=df_train, x='SibSp', kde=True, ax=ax[0, 0])\n",
    "ax[0, 0].set_title('Siblings and Spouses Distribution Histogram')\n",
    "\n",
    "sns.boxplot(data=df_train, x='SibSp', ax=ax[0, 1])\n",
    "ax[0, 1].set_title('Siblings and Spouses Distribution Boxplot')\n",
    "\n",
    "sns.histplot(data=df_train, x='Parch', kde=True, ax=ax[1, 0])\n",
    "ax[1, 0].set_title('Parents and Children Distribution Histogram')\n",
    "\n",
    "sns.boxplot(data=df_train, x='Parch', ax=ax[1, 1])\n",
    "ax[1, 1].set_title('Parents and Children Distribution Boxplot')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Over **600** passengers traveling alone.\n",
    "- There are also over **100** passengers traveling with 1 person.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1.7 Analysis of Embarked\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 2, figsize=(20, 7))\n",
    "g = sns.countplot(data=df_train, x='Embarked', order=['S', 'C', 'Q'], ax=ax[0])\n",
    "ax[0].set_title('Bar Chart')\n",
    "\n",
    "df_train['Embarked'].value_counts().plot(kind='pie', autopct=\"%1.1f%%\", ax=ax[1])\n",
    "ax[1].set_title('Pie Chart')\n",
    "\n",
    "bar_plot_annotate(g, 'Embarked')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Most of the passengers, approximately **72.4%** boarded the Titanic from Southampton.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 Multivariate Analysis\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This function will be used to annotate bar plots with multiple features."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def stacked_bar_plot_annotate(axes, column, order=None):\n",
    "    for _i in range(len(sorted(df_train[column].dropna().unique()))):\n",
    "        b1 = df_train.groupby(column)['Survived'].value_counts().loc[order[_i], 1]\n",
    "        b2 = df_train.groupby(column)['Survived'].value_counts().loc[order[_i], 0]\n",
    "        _x = axes.patches[_i].get_x() + g.patches[_i].get_width() / 2\n",
    "        axes.annotate(text=b1, xy=(_x, b1 / 2), ha='center', va='center')\n",
    "        axes.annotate(text=b2, xy=(_x, b1 + b2 / 2), ha='center', va='center')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2.1 Analysis of Survived and Age\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 7))\n",
    "sns.histplot(data=df_train, x='Age', hue='Survived', multiple='stack', kde=True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "number_of_survival_under_10 = df_train[(df_train['Age'] <= 10) & (df_train['Survived'] == 1)].shape[0]\n",
    "number_of_survival_over_65 = df_train[(df_train['Age'] >= 65) & (df_train['Survived'] == 1)].shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Number of people survived in 0-10 age range: {number_of_survival_under_10}')\n",
    "print(f'Number of people survived in 65+ age range: {number_of_survival_over_65}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- The **0-10** age range has a higher rate of survival. Maybe kids had a higher priority for the lifeboats.\n",
    "- The **65+** age range has an extremely low rate of survival. This outcome may have happened because elders have a relatively low physical capacity to survive.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2.2 Analysis of Survived and Sex\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 7))\n",
    "g = sns.histplot(data=df_train, x='Sex', hue='Survived', multiple='stack')\n",
    "\n",
    "stacked_bar_plot_annotate(g, 'Sex', order=['female', 'male'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in ['female', 'male']:\n",
    "    survived = df_train[(df_train['Sex'] == i) & (df_train['Survived'] == 1)].shape[0]\n",
    "    total = df_train[df_train['Sex'] == i].shape[0]\n",
    "    print(f'{survived / total * 100 :.2f}% of the {i} passengers survived.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Most of the survivors are **female**.\n",
    "- Huge amount of female passengers survived.\n",
    "- Small amount of male passengers survived.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2.3 Analysis of Survived and Pclass\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 7))\n",
    "ax = sns.histplot(data=df_train, x='Pclass', hue='Survived', multiple='stack', discrete=True)\n",
    "ax.set_xticks([1, 2, 3])\n",
    "\n",
    "stacked_bar_plot_annotate(ax, 'Pclass', order=[1, 2, 3])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(1, 4):\n",
    "    survived = df_train[(df_train['Pclass'] == i) & (df_train['Survived'] == 1)].shape[0]\n",
    "    total = df_train[df_train['Pclass'] == i].shape[0]\n",
    "    print(f'{survived / total * 100 :.2f}% of the Pclass-{i} passengers survived.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Upper-class people survived more compared Middle and Lower class people.\n",
    "- Maybe Upper-class people had a higher priority in the rescue process.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2.4 Analysis of Survived and Embarked\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 7))\n",
    "ax = sns.histplot(data=df_train, x='Embarked', hue='Survived', multiple='stack', discrete=True)\n",
    "\n",
    "stacked_bar_plot_annotate(ax, 'Embarked', order=['C', 'Q', 'S'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i, k in {\"C\": \"Cherbourg\", \"Q\": \"Queenstown\", \"S\": \"Southampton\"}.items():\n",
    "    survived = df_train[(df_train['Embarked'] == i) & (df_train['Survived'] == 1)].shape[0]\n",
    "    total = df_train[df_train['Embarked'] == i].shape[0]\n",
    "    print(f'{survived / total * 100 :.2f}% of the passengers embarked in {k} survived.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Most of the passengers who survived are boarded from **Southampton**. This may be due to the fact that **Southampton** is the most crowded port.\n",
    "- More than **50%** of the passengers who boarded from **Cherbourg** survived.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2.5 Analysis of Survived and SipSb\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 7))\n",
    "sns.histplot(data=df_train, x='SibSp', hue='Survived', multiple='stack', kde=True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2.6 Analysis of Survived and Parch\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 7))\n",
    "sns.histplot(data=df_train, x='Parch', hue='Survived', multiple='stack', kde=True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Feature Engineering\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 7))\n",
    "sns.heatmap(data=df_train.corr(), annot=True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "When we look at the relations between `Survived` and other features, we observe:\n",
    "\n",
    "- `PassengerId` has a low negative correlation with `Survived`, approximately **-0.005**.\n",
    "- `Pclass` has a high negative correlation with `Survived`, approximately **-0.34**.\n",
    "- `Fare` has a high positive relation with `Survived`, approximately **0.26**.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 PassengerId\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train['PassengerId']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**PassengerId** column contains **891** unique values for each passenger. Meaning that we can't use this feature because it does not contain any valuable information for us. We are removing this column from the dataset.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.drop('PassengerId', axis=1, inplace=True)\n",
    "df_test.drop('PassengerId', axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 Name\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train['Name']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Name column contains unique values for each passenger. Meaning that we can't use this feature because it does not contain any valuable information for us. We are removing this column from the dataset.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.drop(labels='Name', axis=1, inplace=True)\n",
    "df_test.drop(labels='Name', axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3 Ticket\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train['Ticket']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Ticket** column contains **891** unique values for each passenger. These values are not valuable for us. Therefore, we are removing this column from the dataset.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.drop(labels='Ticket', axis=1, inplace=True)\n",
    "df_test.drop(labels='Ticket', axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.4 Cabin\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train['Cabin']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Missing cabin values in train data: {df_train[\"Cabin\"].isna().sum() / df_train[\"Cabin\"].shape[0] * 100:.2f}%')\n",
    "print(f'Missing cabin values in test data: {df_test[\"Cabin\"].isna().sum() / df_test[\"Cabin\"].shape[0] * 100:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Cabin** column contains too many **(77.10%)** missing values. That is why we are removing this from the dataset.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.drop(labels='Cabin', axis=1, inplace=True)\n",
    "df_test.drop(labels='Cabin', axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.5 Age\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train['Age']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Missing age values in train data: {df_train[\"Age\"].isna().sum() / df_train[\"Age\"].shape[0] * 100:.2f}%')\n",
    "print(f'Missing age values in test data: {df_test[\"Age\"].isna().sum() / df_test[\"Age\"].shape[0] * 100:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are missing values in the **Age** column. Amount of missing values are not too much **(19.87%)**. This is why we will try to do data imputation on this feature.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='median')\n",
    "imputer = imputer.fit(df_train[['Age']])\n",
    "df_train['Age'] = imputer.transform(df_train[['Age']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "imputer = imputer.fit(df_test[['Age']])\n",
    "df_test['Age'] = imputer.transform(df_test[['Age']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.6 Fare\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train['Fare']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Number of missing fare values in train data: {df_train[\"Fare\"].isna().sum()}')\n",
    "print(f'Number of missing fare values in test data: {df_test[\"Fare\"].isna().sum()}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is only a single missing value in test data. This is why we will try to do data imputation on this feature.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "imputer = imputer.fit(df_test[['Fare']])\n",
    "df_test['Fare'] = imputer.transform(df_test[['Fare']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.7 Embarked\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train['Embarked']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Number of missing embarked values in train data: {df_train[\"Embarked\"].isna().sum()}')\n",
    "print(f'Number of missing embarked values in test data: {df_test[\"Embarked\"].isna().sum()}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are only 2 missing values in train data. Similar to previous features, we will do data imputation on this feature.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "imputer.fit(df_train[['Embarked']])\n",
    "df_train[['Embarked']] = imputer.transform(df_train[['Embarked']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will also use **OneHotEncoder** to extract separate features from this column. We will create **C**, **Q**, and **S** features which will represent **Cherbourg**, **Queenstown**, and **Southampton**.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoder = encoder.fit(df_train[['Embarked']])\n",
    "df_train[['C', 'Q', 'S']] = encoder.transform(df_train[['Embarked']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder = encoder.fit(df_test[['Embarked']])\n",
    "df_test[['C', 'Q', 'S']] = encoder.transform(df_test[['Embarked']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We successfully separated the **Embarked** column into **C**, **Q**, and **S** columns. Now we can remove the **Embarked** column itself because we don't need it anymore.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.drop(labels='Embarked', axis=1, inplace=True)\n",
    "df_test.drop(labels='Embarked', axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.8 Sex\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train['Sex']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Number of missing sex values in train data: {df_train[\"Sex\"].isna().sum()}')\n",
    "print(f'Number of missing sex values in test data: {df_test[\"Sex\"].isna().sum()}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- We don't have **any** missing values in **Sex** column. Therefore, we can use this feature. We convert this category to a vector.\n",
    "- Similar to **Embarked**, we will again use **OneHotEncoder** to extract separate features from this column. We will create **Female** and **Male** features.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoder = encoder.fit(df_train[['Sex']])\n",
    "df_train[['Female', 'Male']] = encoder.transform(df_train[['Sex']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder = encoder.fit(df_test[['Sex']])\n",
    "df_test[['Female', 'Male']] = encoder.transform(df_test[['Sex']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We successfully separated the **Sex** column into **Female** and **Male** columns. Now we can remove the **Sex** column itself because we don't need it anymore.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.drop(labels='Sex', axis=1, inplace=True)\n",
    "df_test.drop(labels='Sex', axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.9 Parch and SibSp\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will combine **Parch** and **SibSp** columns into a single feature called **FamilySize**.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train['FamilySize'] = df_train['SibSp'] + df_train['Parch']\n",
    "df_test['FamilySize'] = df_test['SibSp'] + df_test['Parch']\n",
    "df_train.drop(labels=['SibSp', 'Parch'], axis=1, inplace=True)\n",
    "df_test.drop(labels=['SibSp', 'Parch'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train = df_train.drop(labels='Survived', axis=1)\n",
    "y_train = df_train['Survived'].copy()\n",
    "X_test = df_test.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Model Building\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are done with the data preparation. Now, we are going to build our Machine Learning model.\n",
    "We are going to use the models below:\n",
    "\n",
    "- Logistic Regression\n",
    "- K-Nearest Neighbor (KNN)\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- Support Vector Machine\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.1 Model Comparison\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "estimators = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'K-Nearest Neighbor': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Support Vector Machine': SVC()\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will use `cross-validation` to compare our models.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cv_scores = pd.DataFrame(columns=[\"Estimator\", \"F1-Score\", \"Accuracy\", \"Overall\"])\n",
    "\n",
    "\n",
    "def compare_models(estimator=estimators, cv=10):\n",
    "    global cv_scores\n",
    "    for name, est in estimator.items():\n",
    "        cv_pred = cross_val_predict(estimator=est, X=X_train, y=y_train, cv=cv)\n",
    "        cv_score = cross_validate(estimator=est, X=X_train, y=y_train, cv=cv, scoring=(['f1', 'accuracy']))\n",
    "        cv_scores = cv_scores.append({\n",
    "            \"Estimator\": name,\n",
    "            \"F1-Score\": cv_score[\"test_f1\"].mean(),\n",
    "            \"Accuracy\": cv_score[\"test_accuracy\"].mean(),\n",
    "            \"Overall\": (cv_score[\"test_f1\"].mean() + cv_score[\"test_accuracy\"].mean()) / 2\n",
    "        }, ignore_index=True)\n",
    "        print(f'\\nClassification Report for {name}')\n",
    "        print(classification_report(y_true=y_train, y_pred=cv_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "compare_models()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will look at the **F1-Score** and **Accuracy** to decide which model performs better without tuning.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cv_scores.sort_values('Overall', ascending=False).reindex(\n",
    "    columns=['Estimator', 'F1-Score', 'Accuracy', 'Overall']).set_index('Estimator')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that **Random Forest** performs best out of all. That's why we will continue with the **RandomForestClassifier**.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2 Hyperparameter Tuning\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will use **Randomized Searching** to find the best hyperparameter values for the **RandomForestClassifier**."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_estimators = np.linspace(50, 500, int((500 - 50) / 20), dtype=int)\n",
    "max_depth = [5, 10, 50, 100, 200, 300, 400, 500]\n",
    "min_samples_split = [2, 4, 6, 8, 10]\n",
    "max_features = ['sqrt', 'log2']\n",
    "bootstrap = [True, False]\n",
    "\n",
    "params = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'max_features': max_features,\n",
    "    'bootstrap': bootstrap\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "random_search_cv = RandomizedSearchCV(\n",
    "    estimator=rfc,\n",
    "    param_distributions=params,\n",
    "    n_iter=100,\n",
    "    cv=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search = random_search_cv.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We found the best parameters from fitting the **Randomized Search**."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "search.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will compare our base **Random Forest** model to the one with these parameters to figure out the amount of improvement we achieved."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_model = RandomForestClassifier(n_estimators=478,\n",
    "                                    min_samples_split=10,\n",
    "                                    max_features='sqrt',\n",
    "                                    max_depth=10,\n",
    "                                    bootstrap=False,\n",
    "                                    random_state=42)\n",
    "\n",
    "best_model_score = cross_validate(estimator=best_model, X=X_train, y=y_train, cv=10, scoring=(['f1', 'accuracy']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_model_df = pd.DataFrame(data=best_model_score, columns=['F1-Score', 'Accuracy', 'Overall'], index=['Best Random Model'])\n",
    "best_model_df.loc['Best Random Model', 'F1-Score'] = best_model_score[\"test_f1\"].mean()\n",
    "best_model_df.loc['Best Random Model', 'Accuracy'] = best_model_score[\"test_accuracy\"].mean()\n",
    "best_model_df.loc['Best Random Model', 'Overall'] = (best_model_score[\"test_f1\"].mean() +\n",
    "                                                     best_model_score[\"test_accuracy\"].mean()) / 2\n",
    "comparison = cv_scores[cv_scores['Estimator'] == 'Random Forest'].set_index('Estimator')\n",
    "comparison = comparison.append(best_model_df).sort_values('Overall', ascending=False)\n",
    "comparison = comparison.rename(index={'Random Forest': 'Base Model'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "comparison"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_random_overall = comparison.loc['Best Random Model', 'Overall']\n",
    "base_overall = comparison.loc['Base Model', 'Overall']\n",
    "print(f'Improvement: {(best_random_overall - base_overall) / base_overall * 100 :.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We achieved **3.04%** improvement over our base Random Forest model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN8MbHGkthOn411TzZ+ca3d",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "titanic.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.10.5 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "f136e80638ce9a09a25d30dfd0e6bb08ee658f0288d9ebfb89bd7588334d0c37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}